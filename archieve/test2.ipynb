{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import api_key_qwen\n",
    "from aiModel import QwenModel\n",
    "from ai import call_model\n",
    "\n",
    "\n",
    "def table_sum_agent(structure,samples):\n",
    "    tools = [\n",
    "        {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"save_summary\",\n",
    "            \"description\": \"将总结信息保存到数据库中。包对对整个表格以及每一列字段的总结。\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"table_summary\": {\n",
    "                        \"description\": \"对表格功能用户的一句话总结\",\n",
    "                        \"type\": \"string\"\n",
    "                    },\n",
    "                        \"column_summaries\": {\n",
    "                        \"description\": \"\"\"\n",
    "                        对每一个字段的一个总结，{\n",
    "                            \"column1_name\": \"Summary for column 1 based on the samples and structure.\",\n",
    "                            \"column2_name\": \"Summary for column 2 based on the samples and structure.\"}\n",
    "                            \"\"\",\n",
    "                        \"type\": \"dict\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"table_summary\"]\n",
    "            },\n",
    "        },\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    role_setting = '''\n",
    "    Prompt: \"根据表格的结构和样本条目，总结表格的整体用途和每列存储的信息类型。为表格的总体用途生成一句详尽的总结，并为每一列创建一个详尽的总结字典。使用'save_summary'函数保存这些总结。\"\n",
    "\n",
    "\n",
    "任务:\n",
    "1. 分析表格结构，确定其预定功能。\n",
    "2. 查看样本条目，了解每一列存储的数据类型及其对表格功能的贡献。\n",
    "3. 生成表格目的的详尽单句总结。\n",
    "4. 创建一个字典，为每一列生成总结，说明基于结构和样本的信息类型。\n",
    "5. 使用'save_summary'工具将生成的总结保存到数据库中。\n",
    "\n",
    "工具:\n",
    "- save_summary: 将生成的总结保存到数据库中的函数。该函数需要表格的一句话总结和每一列的总结字典。\n",
    "\n",
    "预期输出:\n",
    "- 表格整体的一句话总结。\n",
    "- 包含每列总结的字典。\n",
    "- 成功执行'save_summary'函数以保存这些总结。\n",
    "\n",
    "确保总结的准确性和相关性以符合所提供的结构和样本数据，并遵守使用'save_summary'函数的所需格式和详细要求。\n",
    "\n",
    "      '''\n",
    "    messages = [{\"role\": \"system\",\"content\": role_setting}]\n",
    "    messages.append({\"role\": \"user\",\"content\": '数据表结构是：' + structure})\n",
    "    messages.append({\"role\": \"user\",\"content\": '表格样本条目是：' + samples})\n",
    "    \n",
    "    model_name = \"qwen-plus\" \n",
    "    response = QwenModel(api_key=api_key_qwen, model=model_name, temperature=0.2,tools=tools)\n",
    "    total_usage = 0\n",
    "    call_model(response, messages)\n",
    "    messages.append(response.message_to_append)\n",
    "    total_usage += response.total_tokens\n",
    "\n",
    "    max_loop_count = 10\n",
    "    loop_count = 0\n",
    "    while loop_count < max_loop_count and response.tool_calls:\n",
    "        args = response.function_args\n",
    "\n",
    "        if response.function_name == \"save_summary\":\n",
    "            try:\n",
    "                # function_result = save_summary(**json.loads(args))\n",
    "                return args\n",
    "            except Exception as e:\n",
    "                function_result = {\"error\": str(e)}\n",
    "\n",
    "        messages.append({\n",
    "            \"role\": \"tool\",\n",
    "            \"content\": f\"{function_result}\",\n",
    "            \"tool_call_id\":response.tool_calls['id']\n",
    "        })\n",
    "        \n",
    "        call_model(response, messages)\n",
    "        total_usage += response.total_tokens\n",
    "        messages.append(response.message_to_append)\n",
    "    return response.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "import json\n",
    "\n",
    "# 建立数据库连接\n",
    "connection = mysql.connector.connect(\n",
    "    host=\"gz-cdb-5scrcjb5.sql.tencentcdb.com\",\n",
    "    user=\"db\",\n",
    "    password=\"dbdb905905\",\n",
    "    database=\"sele\",\n",
    "    port=63432\n",
    ")\n",
    "\n",
    "def get_tables(cursor):\n",
    "    cursor.execute(\"SHOW TABLES\")\n",
    "    return [table[0] for table in cursor.fetchall()]\n",
    "\n",
    "def get_table_structure(cursor, table_name):\n",
    "    cursor.execute(f\"SHOW CREATE TABLE {table_name}\")\n",
    "    return cursor.fetchone()[1]\n",
    "\n",
    "def get_sample_data(cursor, table_name):\n",
    "    cursor.execute(f\"SELECT * FROM {table_name} LIMIT 5\")\n",
    "    rows = cursor.fetchall()\n",
    "    # 将行数据转换成字符串，以便传递给AI分析器\n",
    "    sample_str = \"\\n\".join([str(row) for row in rows])\n",
    "    return sample_str\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def main():\n",
    "    cursor = connection.cursor()\n",
    "    tables = get_tables(cursor)\n",
    "    results = []\n",
    "\n",
    "    for table in tables:\n",
    "        structure = get_table_structure(cursor, table)\n",
    "        samples = get_sample_data(cursor, table)\n",
    "        response = table_sum_agent(structure, samples)\n",
    "        table_summary, columns_summary = table_sum_agent(**json.loads(response))\n",
    "        results.append({\n",
    "            \"table\": table,\n",
    "            \"summary\": table_summary,\n",
    "            \"columns\": columns_summary\n",
    "        })\n",
    "\n",
    "    cursor.close()\n",
    "    connection.close()\n",
    "\n",
    "    # 将结果保存为JSON文件\n",
    "    with open('database_summary.json', 'w') as f:\n",
    "        json.dump(results, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain_community.embeddings import DashScopeEmbeddings\n",
    "import json\n",
    "\n",
    "# 假设已经有一个包含数据库所有表及其字段摘要的JSON文件\n",
    "with open('database_summary.json', 'r') as f:\n",
    "    database_summary = json.load(f)\n",
    "\n",
    "# 提取字段总结和对应的字段名\n",
    "field_summaries = []\n",
    "metadata_list = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "for table in database_summary:\n",
    "    # 对表级总结的处理\n",
    "    field_summaries.append(table[\"summary\"])\n",
    "    metadata_list.append({\"field_name\": \"\", \"table_name\": table[\"table\"]})\n",
    "\n",
    "    # 对字段级总结的处理\n",
    "    for column_name, column_summary in table[\"columns\"].items():\n",
    "        field_summaries.append(column_summary)  # 直接使用字段摘要字符串\n",
    "        metadata_list.append({\"field_name\": column_name, \"table_name\": table[\"table\"]})\n",
    "\n",
    "# 初始化 DashScope 嵌入模型\n",
    "embeddings = DashScopeEmbeddings(\n",
    "    model=\"text-embedding-v1\", dashscope_api_key=\"sk-cbcc1fb859b1456885a270eecbec6369\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# 对每个总结进行嵌入\n",
    "vecs = embeddings.embed_documents(field_summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "186\n"
     ]
    }
   ],
   "source": [
    "print(len(field_summaries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "186\n",
      "<class 'list'>\n",
      "<class 'list'>\n",
      "1536\n",
      "<class 'float'>\n"
     ]
    }
   ],
   "source": [
    "print(len(vecs))\n",
    "print(type(vecs))\n",
    "print(type(vecs[0]))\n",
    "print(len(vecs[0]))\n",
    "print(type(vecs[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'embed_documents'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[79], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 初始化向量存储,并添加嵌入向量和元数据\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m vector_store \u001b[38;5;241m=\u001b[39m \u001b[43mChroma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_texts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtexts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfield_summaries\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvecs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata_list\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tenderchat/lib/python3.11/site-packages/langchain_community/vectorstores/chroma.py:736\u001b[0m, in \u001b[0;36mChroma.from_texts\u001b[0;34m(cls, texts, embedding, metadatas, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001b[0m\n\u001b[1;32m    728\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mchromadb\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbatch_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m create_batches\n\u001b[1;32m    730\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m create_batches(\n\u001b[1;32m    731\u001b[0m         api\u001b[38;5;241m=\u001b[39mchroma_collection\u001b[38;5;241m.\u001b[39m_client,\n\u001b[1;32m    732\u001b[0m         ids\u001b[38;5;241m=\u001b[39mids,\n\u001b[1;32m    733\u001b[0m         metadatas\u001b[38;5;241m=\u001b[39mmetadatas,\n\u001b[1;32m    734\u001b[0m         documents\u001b[38;5;241m=\u001b[39mtexts,\n\u001b[1;32m    735\u001b[0m     ):\n\u001b[0;32m--> 736\u001b[0m         \u001b[43mchroma_collection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_texts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    737\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtexts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    738\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    739\u001b[0m \u001b[43m            \u001b[49m\u001b[43mids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    740\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    741\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    742\u001b[0m     chroma_collection\u001b[38;5;241m.\u001b[39madd_texts(texts\u001b[38;5;241m=\u001b[39mtexts, metadatas\u001b[38;5;241m=\u001b[39mmetadatas, ids\u001b[38;5;241m=\u001b[39mids)\n",
      "File \u001b[0;32m~/anaconda3/envs/tenderchat/lib/python3.11/site-packages/langchain_community/vectorstores/chroma.py:275\u001b[0m, in \u001b[0;36mChroma.add_texts\u001b[0;34m(self, texts, metadatas, ids, **kwargs)\u001b[0m\n\u001b[1;32m    273\u001b[0m texts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(texts)\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embedding_function \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 275\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_embedding_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_documents\u001b[49m(texts)\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m metadatas:\n\u001b[1;32m    277\u001b[0m     \u001b[38;5;66;03m# fill metadatas with empty dicts if somebody\u001b[39;00m\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;66;03m# did not specify metadata for all texts\u001b[39;00m\n\u001b[1;32m    279\u001b[0m     length_diff \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(texts) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(metadatas)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'embed_documents'"
     ]
    }
   ],
   "source": [
    "# 初始化向量存储,并添加嵌入向量和元数据\n",
    "vector_store = Chroma.from_texts(\n",
    "    texts=field_summaries, \n",
    "    embedding=vecs, \n",
    "    metadatas=metadata_list\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 搜索\n",
    "query = \"我需要找到存储客户地址的字段\"\n",
    "results = vector_store.similarity_search(query, k=2)\n",
    "\n",
    "print(f\"相关字段名:\")\n",
    "for result in results:\n",
    "    metadata = result.metadata\n",
    "    if metadata[\"field_name\"]:  # 确保不显示表级总结\n",
    "        print(f\"{metadata['table_name']}.{metadata['field_name']}\")  # 显示表名和字段名\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'embed_documents'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[66], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m vecs \u001b[38;5;241m=\u001b[39m embeddings\u001b[38;5;241m.\u001b[39membed_documents(texts)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# 初始化 Chroma 向量存储\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m vector_store \u001b[38;5;241m=\u001b[39m \u001b[43mChroma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_texts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtexts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvecs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msource\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mexample\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# 进行相似性搜索\u001b[39;00m\n\u001b[1;32m     25\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat is an example sentence?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/tenderchat/lib/python3.11/site-packages/langchain_community/vectorstores/chroma.py:736\u001b[0m, in \u001b[0;36mChroma.from_texts\u001b[0;34m(cls, texts, embedding, metadatas, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001b[0m\n\u001b[1;32m    728\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mchromadb\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbatch_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m create_batches\n\u001b[1;32m    730\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m create_batches(\n\u001b[1;32m    731\u001b[0m         api\u001b[38;5;241m=\u001b[39mchroma_collection\u001b[38;5;241m.\u001b[39m_client,\n\u001b[1;32m    732\u001b[0m         ids\u001b[38;5;241m=\u001b[39mids,\n\u001b[1;32m    733\u001b[0m         metadatas\u001b[38;5;241m=\u001b[39mmetadatas,\n\u001b[1;32m    734\u001b[0m         documents\u001b[38;5;241m=\u001b[39mtexts,\n\u001b[1;32m    735\u001b[0m     ):\n\u001b[0;32m--> 736\u001b[0m         \u001b[43mchroma_collection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_texts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    737\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtexts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    738\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    739\u001b[0m \u001b[43m            \u001b[49m\u001b[43mids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    740\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    741\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    742\u001b[0m     chroma_collection\u001b[38;5;241m.\u001b[39madd_texts(texts\u001b[38;5;241m=\u001b[39mtexts, metadatas\u001b[38;5;241m=\u001b[39mmetadatas, ids\u001b[38;5;241m=\u001b[39mids)\n",
      "File \u001b[0;32m~/anaconda3/envs/tenderchat/lib/python3.11/site-packages/langchain_community/vectorstores/chroma.py:275\u001b[0m, in \u001b[0;36mChroma.add_texts\u001b[0;34m(self, texts, metadatas, ids, **kwargs)\u001b[0m\n\u001b[1;32m    273\u001b[0m texts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(texts)\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embedding_function \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 275\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_embedding_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_documents\u001b[49m(texts)\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m metadatas:\n\u001b[1;32m    277\u001b[0m     \u001b[38;5;66;03m# fill metadatas with empty dicts if somebody\u001b[39;00m\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;66;03m# did not specify metadata for all texts\u001b[39;00m\n\u001b[1;32m    279\u001b[0m     length_diff \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(texts) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(metadatas)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'embed_documents'"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "# 初始化嵌入模型\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=\"sk-proj-CmkZhJbSwXJv3FNYMv49T3BlbkFJHpq8bV7zuQOpe7ikfiSN\")\n",
    "\n",
    "# 准备文本数据\n",
    "texts = [\n",
    "    \"This is the first sentence.\",\n",
    "    \"Here is another sentence.\",\n",
    "    \"One more sentence for the example.\"\n",
    "]\n",
    "\n",
    "# 获取文本嵌入向量\n",
    "vecs = embeddings.embed_documents(texts)\n",
    "\n",
    "# 初始化 Chroma 向量存储\n",
    "vector_store = Chroma.from_texts(\n",
    "    texts=texts,\n",
    "    embedding=vecs,\n",
    "    metadatas=[{\"source\": \"example\"}] * len(texts)\n",
    ")\n",
    "\n",
    "# 进行相似性搜索\n",
    "query = \"What is an example sentence?\"\n",
    "docs = vector_store.similarity_search(query)\n",
    "\n",
    "print(docs[0].page_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chroma version: 0.5.0\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "print(f\"Chroma version: {chromadb.__version__}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tenderchat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
